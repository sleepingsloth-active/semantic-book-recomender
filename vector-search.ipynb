{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3e2e496ba9ef80",
   "metadata": {},
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93b2ed83bb978ac3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('books_cleaned.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b266fdcc17fcaf6f",
   "metadata": {},
   "source": [
    "books"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98806c3046c5930c",
   "metadata": {},
   "source": [
    "books[\"tagged_description\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e2dfa1ca97c68ac",
   "metadata": {},
   "source": [
    "#filtering by appending the isbn as an identifier so what we can do is when we get back the recommendations we can split the isbn from the description  as use that as the thing to filter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62df5f2e6756cba8",
   "metadata": {},
   "source": [
    "#text loader method in lang chain it doesnot work with pandas data frame so first thing we do is save these tagged description and only the tag description in a text file"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44eba80e73c5acc0",
   "metadata": {},
   "source": [
    "#using 2 csv method in pandas to change into text file and make sure its seperated by new lines\n",
    "#doesnot have an index and header\n",
    "#just a file that contains just text description\n",
    "\n",
    "#If you're exporting just one column as text with new lines:\n",
    "books[\"tagged_description\"].to_csv(\"tagged_description.txt\",index=False,header=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7eb44ba53a27ca0",
   "metadata": {},
   "source": [
    "#step 1 load the text using text loader method\n",
    "#Why not use chunk_size=0?LangChain does not officially support chunk_size=0. It may seem to work in rare cases, but:Itâ€™s not reliable across versions.It can throw unexpected ValueError or cause incorrect splits.Official documentation recommends setting a large enough chunk size if you want to split purely on a separator.\n",
    "# Step 1: Load the text file using utf-8 encoding\n",
    "loader = TextLoader(\"tagged_description.txt\", encoding=\"utf-8\")\n",
    "raw_documents = loader.load()\n",
    "# Step 2: Split by newlines (1 description per document)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=10000,  # Very large so each line becomes its own chunk\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18ab097f4677fd69",
   "metadata": {},
   "source": [
    "documents[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76dc0270366b2d7d",
   "metadata": {},
   "source": [
    "#use chroma to assign that to a variable called db books and use the form documents method in chroma and pass that two arguments ,we are going to pass in the documents that we created the ones that have been split using text splitter and tell it what embedding we want to use and we use our open ai embeddings\n",
    "# Use HuggingFace embeddings model that runs locally\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "db_books = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"  # this is crucial\n",
    ")\n",
    "db_books.persist()  # this saves the database to disk\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "316065738c9056b7",
   "metadata": {},
   "source": [
    "query=\"A book to teach children about nature\"\n",
    "docs = db_books.similarity_search(query,k=5)#k=no of outputs we want/get top 5 similar docs\n",
    "docs\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "isbn_str = docs[0].page_content.split()[0].strip('\":')  # Remove quotes and colon\n",
    "isbn = int(isbn_str)\n",
    "filtered_books = books[books[\"isbn13\"] == isbn]\n",
    "filtered_books"
   ],
   "id": "f1bce1cd79b568bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#bundle this functionality into a function so we can do this for every query we want to do and its going to return all the recomendation\n",
    "def get_all_recommendations(docs, books_df):\n",
    "    isbns = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            isbn = doc.page_content.split()[0].strip('\":')\n",
    "            if books_df[\"isbn13\"].dtype == \"int64\":\n",
    "                isbn = int(isbn)\n",
    "            isbns.append(isbn)\n",
    "        except Exception as e:\n",
    "            print(\"Skipped one doc due to error:\", e)\n",
    "\n",
    "    return books_df[books_df[\"isbn13\"].isin(isbns)]\n"
   ],
   "id": "fa3354fb7310ffe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recommended_books = get_all_recommendations(docs, books)\n",
    "recommended_books"
   ],
   "id": "9065ae755d4109db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"crime and punishment\"\n",
    "docs = db_books.similarity_search(query, k=5)  # get top 10 similar documents\n",
    "recommended_books = get_all_recommendations(docs, books)\n",
    "recommended_books.head()  # shows first 5 rows\n"
   ],
   "id": "c9119bc411d41b18",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
